# EDTH Hackathon London 2025

Real-time object detection and tracking system for the European Defence Tech Hackathon in London 2025.

See [this information spreadsheet](https://docs.google.com/spreadsheets/d/1AT8ndsEe9hgljTUFgmpAJ_pYE9kLxrVdJI-xuT68uto/edit?referrer=luma&gid=2054763765).
Data is available through [this sharepoint](https://quantumdrones-my.sharepoint.com/personal/pzimmermann_quantum-systems_com/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fpzimmermann%5Fquantum%2Dsystems%5Fcom%2FDocuments%2F2025%5FLondon%5FHackathon&ga=1).

## ğŸ¯ Project Features

**Complete real-time object detection and tracking pipeline** tackling Quantum-6 (and Stark-1):

âœ… **Real-time object detection** using YOLO11  
âœ… **Multi-object tracking** with ByteTrack (persistent IDs)  
âœ… **Robust re-identification** with appearance and kinematic features  
âœ… **Live web interface** with interactive visualization  
âœ… **Camera and video file support**  
âœ… **Database integration** for session history  
âœ… **Interactive tooltips** with detection details  
âœ… **Performance monitoring** (FPS, object count)  
âœ… **Drone video analysis** with GPS mapping  
âœ… **Video processing and cropping** tools  
âœ… **Comprehensive data visualization** and analysis  

### Core Capabilities

1. **Identify objects in video in real time** - YOLO11 detection with 30+ FPS
2. **Estimate velocity, acceleration, and class** - Multi-object tracking with ByteTrack
3. **Maintain live tracking** - Persistent object IDs across frames with re-identification
4. **Interactive web visualization** - Real-time canvas with detection overlays
5. **Drone video analysis** - GPS mapping and telemetry integration
6. **Database storage and analysis** - SQLite with comprehensive visualization tools

## ğŸš€ Quick Start (Recommended)

### **Option A: Complete Real-time System** ğŸ”´

**For live camera feed and real-time detection:**

```bash
cd standalone-frontend
./start-realtime.sh
```

Then open **http://localhost:5173** and:

1. Toggle to **"ğŸ”´ Live Detection"** mode
2. Click **"Connect"** to connect to real-time server
3. Click **"Start Webcam"** for live camera OR **"Start Sample Video"** for video files
4. **Hover over detections** for detailed information!

**Features:**

- ğŸ¯ **Live camera feed** with real-time object detection
- ğŸ¨ **Interactive visualization** with hover tooltips
- ğŸ“Š **Performance stats** (FPS, object count, frame numbers)
- ğŸ—„ï¸ **Database storage** of detection sessions
- ğŸ”„ **Dual mode**: Live detection + recorded session playback

### **Option B: Recorded Session Viewer** ğŸ“

**To view pre-processed tracking sessions:**

1. First, process a video (see Backend Processing section)
2. Run the standalone frontend:
   ```bash
   cd standalone-frontend
   ./start-realtime.sh
   ```
3. Open **http://localhost:5173** and stay in **"ğŸ“ Recorded Sessions"** mode
4. Select a session to view video with detection overlays

## ğŸ”§ Full Setup Guide

### Prerequisites

**Python 3.11+** and **Node.js 18+** are required.

### 1. Environment Setup

Create and activate a Python virtual environment:

```bash
# Create and activate a virtual environment
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### 2. Install Python Dependencies

Install the backend dependencies using Poetry:

```bash
cd backend
poetry install
```

### 3. **Critical Dependency Fix** âš ï¸

There is a known incompatibility between packages. **You must run these commands or the system will not work:**

```bash
pip install trackers
pip install supervision==0.21.0
pip install websockets  # For real-time server
```

### 4. Install Frontend Dependencies

```bash
cd standalone-frontend
npm install
```

### 5. Add Video Files (Optional)

Place video files in the `data/` directory for processing or use the default sample video.

---

## ğŸ® Usage Options

### ğŸ”´ **Real-time Detection (Recommended)**

**Start the complete system with one command:**

```bash
cd standalone-frontend
./start-realtime.sh
```

This starts:

- ğŸ¯ **Real-time detection server** (ws://localhost:8765)
- ğŸ—„ï¸ **API server** (http://localhost:3001)
- ğŸŒ **Frontend interface** (http://localhost:5173)

**Then:**

1. Open **http://localhost:5173** in your browser
2. Toggle to **"ğŸ”´ Live Detection"** mode
3. Click **"Connect"** â†’ **"Start Webcam"** or **"Start Sample Video"**
4. **Hover over detections** for detailed tooltips!

---

## ğŸ› ï¸ Backend Processing (Advanced)

### **Core Tracking Commands**

All commands use the `make` system for easy execution:

#### **Basic Object Detection & Tracking**

```bash
# Run integrated real-time tracker on default video
make analyse

# Run real-time camera tracking with YOLO11
make realtime_tracker

# Run enhanced kinematic re-identification tracker
make kinematic_reid_tracker
```

#### **Re-identification Tracking**

```bash
# Run re-identification tracker on quantum drone video
make reidentification_tracker
```

#### **Drone Video Analysis**

```bash
# Launch drone video and map viewer with GPS tracking
make map_viewer
```

#### **Video Processing**

```bash
# Crop video using time configuration
make crop
```

### **Database Analysis & Visualization**

```bash
# Show database schema and basic tracking data
make db_visualize

# Show data for specific session
make db_visualize_session SESSION_ID=1

# Show database data with plots
make db_visualize_plots

# Comprehensive database analysis with plots
make db_visualize_all
```

### **Frontend Management**

```bash
# Start frontend application (both recorded and real-time)
make frontend

# Install all frontend and Python dependencies
make frontend_install

# Clean up frontend processes
make frontend_clean
```

### **Advanced Video Processing**

**Generate annotated video output:**

```bash
python backend/tracking/trackers_in_video.py data/your_video.mp4
```

Creates `data/your_video_output.mp4` with bounding boxes.

**Generate database + tracking data:**

```bash
python backend/tracking/integrated_realtime_tracker.py data/your_video.mp4 --headless
```

- Writes to `databases/tracking_data.db`
- Creates `data/your_video_tracking_data.json`

### **Metadata Extraction**

**Extract video metadata and telemetry:**

```bash
python backend/metadata_process/video_metadata_scrape.py data/your_video.mp4
```

**Parse drone telemetry data:**

```bash
python backend/metadata_process/enhanced_telemetry_parser.py data/quantum_drone_flight/metadata.csv
```

### **Session Management**

**Generate detections for existing session:**

```bash
python backend/tracking/generate_session_detections.py --session-id 1 --video-path data/your_video.mp4
```

---

## ğŸ—ï¸ System Architecture

```
ğŸ“¹ Input (Camera/Video)
    â†“
ğŸ¤– YOLO11 Detection
    â†“
ğŸ¯ ByteTrack Multi-Object Tracking
    â†“
ğŸ”„ Re-identification System (Appearance + Kinematic)
    â†“
ğŸŒ WebSocket Streaming
    â†“
âš›ï¸ React Frontend Canvas
    â†“
ğŸ—„ï¸ SQLite Database Storage
    â†“
ğŸ“Š Data Visualization & Analysis
```

## ğŸ“‹ Project Structure

```
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ tracking/                    # Core detection & tracking
â”‚   â”‚   â”œâ”€â”€ integrated_realtime_tracker.py      # Main tracking with DB
â”‚   â”‚   â”œâ”€â”€ realtime_reidentification_tracker.py # Enhanced re-ID tracking
â”‚   â”‚   â”œâ”€â”€ realtime_tracker.py                # Camera tracking
â”‚   â”‚   â”œâ”€â”€ trackers_in_video.py               # Video processing
â”‚   â”‚   â”œâ”€â”€ kinematic_reidentification.py      # Motion-based re-ID
â”‚   â”‚   â”œâ”€â”€ database_integration.py           # DB management
â”‚   â”‚   â””â”€â”€ drone_video_map_viewer.py         # GPS mapping
â”‚   â”œâ”€â”€ db_query/
â”‚   â”‚   â””â”€â”€ data_visualisation.py             # Database analysis
â”‚   â”œâ”€â”€ metadata_process/
â”‚   â”‚   â”œâ”€â”€ video_metadata_scrape.py          # Video metadata extraction
â”‚   â”‚   â””â”€â”€ enhanced_telemetry_parser.py      # Drone telemetry parsing
â”‚   â”œâ”€â”€ video_crop/
â”‚   â”‚   â””â”€â”€ video_crop.py                     # Video cropping tools
â”‚   â””â”€â”€ reidentify/
â”‚       â”œâ”€â”€ robust_reidentification.py        # Appearance-based re-ID
â”‚       â””â”€â”€ reidentification.py              # Core re-ID system
â”œâ”€â”€ standalone-frontend/             # ğŸ”´ Real-time web interface
â”‚   â”œâ”€â”€ start-realtime.sh           # One-command startup
â”‚   â”œâ”€â”€ realtime_server.py          # WebSocket detection server
â”‚   â”œâ”€â”€ src/RealtimeVideoCanvas.tsx # Live detection canvas
â”‚   â””â”€â”€ server.js                   # API for recorded sessions
â”œâ”€â”€ data/                           # Video files and datasets
â”‚   â”œâ”€â”€ quantum_drone_flight/       # Drone video data
â”‚   â”œâ”€â”€ VisDrone2019-MOT-val/       # Validation dataset
â”‚   â””â”€â”€ metadata/                   # Extracted metadata
â”œâ”€â”€ databases/                      # SQLite tracking data
â”œâ”€â”€ models/                         # YOLO model weights
â””â”€â”€ Makefile                       # Command automation
```

## âš¡ Key Features

### **Detection & Tracking**
- **ğŸ¯ Real-time Object Detection**: YOLO11 at 30+ FPS
- **ğŸ”„ Multi-Object Tracking**: ByteTrack with persistent IDs
- **ğŸ” Robust Re-identification**: Appearance + kinematic features
- **ğŸ“Š Live Performance Metrics**: FPS, object count, frame numbers
- **ğŸ“¹ Flexible Input**: Camera feed or video files

### **Visualization & Analysis**
- **ğŸ¨ Interactive Visualization**: Hover tooltips with detection details
- **ğŸ—„ï¸ Session Management**: Database storage and replay
- **ğŸŒ Web-based Interface**: No installation required
- **ğŸ“Š Comprehensive Analytics**: Class distribution, tracking statistics
- **ğŸ—ºï¸ GPS Mapping**: Drone video with location overlays

### **Data Processing**
- **ğŸ“ Video Processing**: Cropping, metadata extraction
- **ğŸ“ˆ Database Analysis**: SQLite with visualization tools
- **ğŸ›°ï¸ Telemetry Integration**: Drone GPS and sensor data
- **ğŸ’¾ Export Capabilities**: JSON, CSV, annotated videos

## ğŸ® Interactive Controls

### **Real-time Detection**
- **Web Interface**: Toggle between live detection and recorded sessions
- **Camera Controls**: Start/stop webcam, select video files
- **Detection Info**: Hover over bounding boxes for details

### **Video Processing**
- **Playback Controls**: Play, pause, seek, frame-by-frame
- **Session Selection**: Choose from processed tracking sessions
- **Data Visualization**: View tracking statistics and plots

## ğŸ› Troubleshooting

**Real-time server won't start?**

- Ensure Python dependencies are installed: `pip install websockets opencv-python ultralytics`
- Check that no other process is using port 8765

**Camera not working?**

- Grant browser camera permissions
- Try different camera IDs in the interface

**Video file not found?**

- Place videos in `data/` directory
- Use relative paths like `data/your_video.mp4`

**Performance issues?**

- Close other resource-intensive applications
- Lower video resolution for better FPS

**Database connection issues?**

- Ensure SQLite database exists in `databases/` directory
- Check file permissions

---

## ğŸ“š Additional Resources

- **ğŸ“– Real-time System Guide**: `standalone-frontend/REALTIME_GUIDE.md`
- **ğŸ¯ Tooltip Demo**: `standalone-frontend/TOOLTIP_DEMO.md`
- **ğŸš€ Quick Start**: `standalone-frontend/QUICKSTART.md`
- **ğŸ“¹ Camera Selection**: `standalone-frontend/CAMERA_SELECTION.md`
- **âš¡ Features Overview**: `standalone-frontend/FEATURES.md`

## ğŸ”§ Development

### **Adding New Features**

1. **Backend**: Add new scripts in `backend/tracking/` or `backend/db_query/`
2. **Frontend**: Modify React components in `standalone-frontend/src/`
3. **Makefile**: Add new commands to `Makefile` for easy access
4. **Database**: Use `database_integration.py` for data storage

### **Testing**

```bash
# Test basic tracking
make analyse

# Test database visualization
make db_visualize

# Test frontend
make frontend
```

---

## ğŸ“„ License

This project is developed for the European Defence Tech Hackathon London 2025.
Developed by Juan Carlos Climent Pardo, Alvaro Ritter, Kenneth Oliver, Kazybek Khairulla, and Lysander Mawby.
